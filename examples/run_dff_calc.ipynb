{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ScanImageTiffReader import ScanImageTiffReader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "import tifffile\n",
    "from scipy.signal import butter, lfilter,find_peaks, gaussian, convolve\n",
    "from ibllib.io.video import *\n",
    "import scipy.ndimage\n",
    "import cv2\n",
    "from matplotlib.animation import FuncAnimation, FFMpegWriter\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import PillowWriter\n",
    "from ScanImageTiffReader import ScanImageTiffReader\n",
    "import json\n",
    "import ast\n",
    "from murphlib.caimage import *\n",
    "from murphlib.tools import *\n",
    "from murphlib.plotting import *\n",
    "from murphlib.regression import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from scipy.stats import zscore\n",
    "\n",
    "plt.rcParams['animation.ffmpeg_path'] = r'D:\\ffmpeg\\bin\\ffmpeg.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_R3\\20240904\n",
      "processing Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_R3\\20240910\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    #  r'Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_R2\\20240815',\n",
    "    #  r'Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_R2\\20240821',\n",
    "     #r'Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_R3\\20240904',\n",
    "     r'Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_R3\\20240910',\n",
    "     r'Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_R3\\20240918',\n",
    "     r'Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_R3\\20240924',\n",
    "    #  r'Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_R2\\20241015',\n",
    "     r'Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_R3\\20241018',\n",
    "    #  r'Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_R2\\20241106',\n",
    "     r'Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_R3\\20241111',\n",
    "    #  #r'Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_L2\\20241115',\n",
    "    #  r'Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_R2\\20241118',\n",
    "    r'Z:\\TM_Lab\\Edward\\Cerebellum_Imaging\\Pcp2-jgcamp8m\\A_R3\\20241119',\n",
    "     \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for path in paths:\n",
    "    subdir = [d for d in os.listdir(path)]\n",
    "    print('processing '+path)\n",
    "    if 'arm1' in subdir:\n",
    "        arm1_img_path = os.path.join(path, 'arm1')\n",
    "        try: \n",
    "            with open(os.path.join(arm1_img_path, 'ca_img_wholefile_metadata.json'), 'r') as json_file:\n",
    "                arm1_img_meta = json.load(json_file)\n",
    "        except:\n",
    "            raw_img_path = find_tif_file(arm1_img_path)\n",
    "            reader=ScanImageTiffReader(raw_img_path)\n",
    "            arm1_img_meta = parse_text_to_dict(reader.metadata())\n",
    "            with open(os.path.join(arm1_img_path, 'ca_img_wholefile_metadata.json'), 'w') as json_file:\n",
    "                json.dump(arm1_img_meta, json_file)\n",
    "        arm1_suite2p_path = os.path.join(arm1_img_path,'suite2p','plane0')\n",
    "        arm1_fluo = np.load(arm1_suite2p_path+'\\\\F.npy', allow_pickle=True)\n",
    "        arm1_neufluo = np.load(arm1_suite2p_path+'\\\\Fneu.npy', allow_pickle=True)\n",
    "        raw_arm1_stat = np.load(arm1_suite2p_path+'\\\\stat.npy', allow_pickle=True)\n",
    "        arm1_iscell = np.load(arm1_suite2p_path+'\\\\iscell.npy', allow_pickle=True)\n",
    "        arm1_iscell = arm1_iscell[:,0]==1\n",
    "        arm1_stat = []\n",
    "        for i, s in enumerate(raw_arm1_stat):\n",
    "            if arm1_iscell[i]:\n",
    "                s['id'] = i\n",
    "                arm1_stat.append(s)\n",
    "        arm1_fluo = arm1_fluo[arm1_iscell,:]\n",
    "        arm1_neufluo = arm1_neufluo[arm1_iscell,:]\n",
    "        frame_rate_arm1 = arm1_img_meta['SI.hRoiManager.scanFrameRate']\n",
    "        try:\n",
    "            arm1_dff = np.load(os.path.join(arm1_img_path, 'dff_moving_percentile.npy'))\n",
    "        except:\n",
    "            arm1_dff = calculate_dff_with_moving_percentile(arm1_fluo, frame_rate=frame_rate_arm1, moving_window=20, percentile=10)\n",
    "            #### only do this if front need to be padded\n",
    "            #arm1_dff = np.hstack([np.zeros((arm1_dff.shape[0],30)), arm1_dff])\n",
    "            np.save(os.path.join(arm1_img_path, 'dff_moving_percentile.npy'), arm1_dff)\n",
    "\n",
    "        arm1_aspect_ratio = np.array([arm1_stat[i]['aspect_ratio'] for i in range(len(arm1_stat))])\n",
    "        arm1_npix = np.array([arm1_stat[i]['npix'] for i in range(len(arm1_stat))])\n",
    "        arm1_pc_idx = np.where((arm1_aspect_ratio<1.1) & (arm1_npix<120) & (arm1_npix>100))[0]\n",
    "        arm1_dd_idx = np.where((arm1_aspect_ratio>1.1) | (arm1_npix>120) | (arm1_npix<100))[0]\n",
    "        arm1_pc_suite2p_idx = np.array([arm1_stat[i]['id'] for i in arm1_pc_idx])\n",
    "        arm1_dd_suite2p_idx = np.array([arm1_stat[i]['id'] for i in arm1_dd_idx])\n",
    "\n",
    "        try:\n",
    "            arm1_dff = np.load(os.path.join(arm1_img_path, 'dff_moving_percentile_pc_lowpass_0p5hz.npy'))\n",
    "        except:\n",
    "            lp_arm1_dff = arm1_dff.copy()\n",
    "            if len(arm1_pc_idx) != 0:\n",
    "                arm1_pc_dff = calculate_dff_with_moving_percentile(arm1_fluo[arm1_pc_idx], frame_rate=frame_rate_arm1, moving_window=60, percentile=50)\n",
    "                lp_arm1_dff[arm1_pc_idx] = arm1_pc_dff\n",
    "            lp_arm1_dff[arm1_pc_idx] = butter_filter(lp_arm1_dff[arm1_pc_idx], cutoff=0.5, fs=frame_rate_arm1, filter_type='low', order=5)\n",
    "            np.save(os.path.join(arm1_img_path, 'dff_moving_percentile_pc_lowpass_0p5hz.npy'), lp_arm1_dff)\n",
    "\n",
    "\n",
    "        frames_metadata_export_path = os.path.join(arm1_img_path, 'ca_img_frames_metadata.json')\n",
    "        img_path = find_tif_file(arm1_img_path)\n",
    "        try:\n",
    "            with open(frames_metadata_export_path, 'r') as json_file:\n",
    "                frames_metadata = json.load(json_file)\n",
    "        except:\n",
    "            \n",
    "            reader=ScanImageTiffReader(img_path)\n",
    "            frames_metadata = []\n",
    "\n",
    "            with ScanImageTiffReader(img_path) as reader:\n",
    "                num_frames = reader.shape()[0]  # Assuming the first dimension represents frames\n",
    "                \n",
    "                for i in range(num_frames):\n",
    "                    description = reader.description(i)\n",
    "                    frame_metadata = {}  # Dictionary to hold this frame's metadata\n",
    "                    \n",
    "                    for line in description.split('\\n'):\n",
    "                        if '=' in line:  # Ensure there's a key-value pair to parse\n",
    "                            key, value = line.split('=', 1)  # Split by the first '='\n",
    "                            key = key.strip()\n",
    "                            \n",
    "                            try:\n",
    "                                # Safely evaluate the value string to the appropriate Python data type\n",
    "                                # This works for numbers, lists, dictionaries, etc.\n",
    "                                value = ast.literal_eval(value.strip())\n",
    "                            except (ValueError, SyntaxError):\n",
    "                                # If evaluation fails, keep the value as a string\n",
    "                                value = value.strip()\n",
    "                            \n",
    "                            frame_metadata[key] = value\n",
    "                    \n",
    "                    frames_metadata.append(frame_metadata)\n",
    "                \n",
    "            with open(frames_metadata_export_path, 'w') as json_file:\n",
    "                json.dump(frames_metadata, json_file)\n",
    "    if 'arm2' in subdir:\n",
    "        arm2_img_path = os.path.join(path, 'arm2')\n",
    "        try: \n",
    "            with open(os.path.join(arm2_img_path, 'ca_img_wholefile_metadata.json'), 'r') as json_file:\n",
    "                arm2_img_meta = json.load(json_file)\n",
    "        except:\n",
    "            raw_img_path = find_tif_file(arm2_img_path)\n",
    "            reader=ScanImageTiffReader(raw_img_path)\n",
    "            arm2_img_meta = parse_text_to_dict(reader.metadata())\n",
    "            with open(os.path.join(arm2_img_path, 'ca_img_wholefile_metadata.json'), 'w') as json_file:\n",
    "                json.dump(arm2_img_meta, json_file)\n",
    "        arm2_suite2p_path = os.path.join(arm2_img_path,'suite2p','plane0')\n",
    "        arm2_fluo = np.load(arm2_suite2p_path+'\\\\F.npy', allow_pickle=True)\n",
    "        arm2_neufluo = np.load(arm2_suite2p_path+'\\\\Fneu.npy', allow_pickle=True)\n",
    "        raw_arm2_stat = np.load(arm2_suite2p_path+'\\\\stat.npy', allow_pickle=True)\n",
    "        arm2_iscell = np.load(arm2_suite2p_path+'\\\\iscell.npy', allow_pickle=True)\n",
    "        arm2_iscell = arm2_iscell[:,0]==1\n",
    "        arm2_stat = []\n",
    "        for i, s in enumerate(raw_arm2_stat):\n",
    "            if arm2_iscell[i]:\n",
    "                s['id'] = i\n",
    "                arm2_stat.append(s)\n",
    "        arm2_fluo = arm2_fluo[arm2_iscell,:]\n",
    "        arm2_neufluo = arm2_neufluo[arm2_iscell,:]\n",
    "        frame_rate_arm2 = arm2_img_meta['SI.hRoiManager.scanFrameRate']\n",
    "        try:\n",
    "            arm2_dff = np.load(os.path.join(arm2_img_path, 'dff_moving_percentile.npy'))\n",
    "        except:\n",
    "            arm2_dff = calculate_dff_with_moving_percentile(arm2_fluo, frame_rate=frame_rate_arm2, moving_window=20, percentile=10)\n",
    "            #### only do this if front need to be padded\n",
    "            #arm2_dff = np.hstack([np.zeros((arm2_dff.shape[0],30)), arm2_dff])\n",
    "            np.save(os.path.join(arm2_img_path, 'dff_moving_percentile.npy'), arm2_dff)\n",
    "        \n",
    "\n",
    "        arm2_aspect_ratio = np.array([arm2_stat[i]['aspect_ratio'] for i in range(len(arm2_stat))])\n",
    "        arm2_npix = np.array([arm2_stat[i]['npix'] for i in range(len(arm2_stat))])\n",
    "        arm2_pc_idx = np.where((arm2_aspect_ratio<1.1) & (arm2_npix<120) & (arm2_npix>100))[0]\n",
    "        arm2_dd_idx = np.where((arm2_aspect_ratio>1.1) | (arm2_npix>120) | (arm2_npix<100))[0]\n",
    "        arm2_pc_suite2p_idx = np.array([arm2_stat[i]['id'] for i in arm2_pc_idx])\n",
    "        arm2_dd_suite2p_idx = np.array([arm2_stat[i]['id'] for i in arm2_dd_idx])\n",
    "\n",
    "        try:\n",
    "            arm2_dff = np.load(os.path.join(arm2_img_path, 'dff_moving_percentile_pc_lowpass_0p5hz.npy'))\n",
    "        except:\n",
    "            lp_arm2_dff = arm2_dff.copy()\n",
    "            if len(arm2_pc_idx) != 0:\n",
    "                arm2_pc_dff = calculate_dff_with_moving_percentile(arm2_fluo[arm2_pc_idx], frame_rate=frame_rate_arm2, moving_window=60, percentile=50)\n",
    "                lp_arm2_dff[arm2_pc_idx] = arm2_pc_dff\n",
    "            lp_arm2_dff[arm2_pc_idx] = butter_filter(lp_arm2_dff[arm2_pc_idx], cutoff=0.5, fs=frame_rate_arm2, filter_type='low', order=5)\n",
    "            np.save(os.path.join(arm2_img_path, 'dff_moving_percentile_pc_lowpass_0p5hz.npy'), lp_arm2_dff)\n",
    "\n",
    "\n",
    "        frames_metadata_export_path = os.path.join(arm2_img_path, 'ca_img_frames_metadata.json')\n",
    "        img_path = find_tif_file(arm2_img_path)\n",
    "        try:\n",
    "            with open(frames_metadata_export_path, 'r') as json_file:\n",
    "                frames_metadata = json.load(json_file)\n",
    "        except:\n",
    "            \n",
    "            reader=ScanImageTiffReader(img_path)\n",
    "            frames_metadata = []\n",
    "\n",
    "            with ScanImageTiffReader(img_path) as reader:\n",
    "                num_frames = reader.shape()[0]  # Assuming the first dimension represents frames\n",
    "                \n",
    "                for i in range(num_frames):\n",
    "                    description = reader.description(i)\n",
    "                    frame_metadata = {}  # Dictionary to hold this frame's metadata\n",
    "                    \n",
    "                    for line in description.split('\\n'):\n",
    "                        if '=' in line:  # Ensure there's a key-value pair to parse\n",
    "                            key, value = line.split('=', 1)  # Split by the first '='\n",
    "                            key = key.strip()\n",
    "                            \n",
    "                            try:\n",
    "                                # Safely evaluate the value string to the appropriate Python data type\n",
    "                                # This works for numbers, lists, dictionaries, etc.\n",
    "                                value = ast.literal_eval(value.strip())\n",
    "                            except (ValueError, SyntaxError):\n",
    "                                # If evaluation fails, keep the value as a string\n",
    "                                value = value.strip()\n",
    "                            \n",
    "                            frame_metadata[key] = value\n",
    "                    \n",
    "                    frames_metadata.append(frame_metadata)\n",
    "                \n",
    "            with open(frames_metadata_export_path, 'w') as json_file:\n",
    "                json.dump(frames_metadata, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arm2_aspect_ratio = np.array([arm2_stat[i]['aspect_ratio'] for i in range(len(arm2_stat))])\n",
    "arm2_npix = np.array([arm2_stat[i]['npix'] for i in range(len(arm2_stat))])\n",
    "arm2_pc_idx = np.where((arm2_aspect_ratio<1.1) & (arm2_npix<120) & (arm2_npix>100))[0]\n",
    "arm2_dd_idx = np.where((arm2_aspect_ratio>1.1) | (arm2_npix>120) | (arm2_npix<100))[0]\n",
    "arm2_pc_suite2p_idx = np.array([arm2_stat[i]['id'] for i in arm2_pc_idx])\n",
    "arm2_dd_suite2p_idx = np.array([arm2_stat[i]['id'] for i in arm2_dd_idx])\n",
    "try:\n",
    "    arm1_dff = np.load(os.path.join(arm1_img_path, 'dff_moving_percentile_pc_lowpass_0p5hz.npy'))\n",
    "    arm2_dff = np.load(os.path.join(arm2_img_path, 'dff_moving_percentile_pc_lowpass_0p5hz.npy'))\n",
    "except:\n",
    "    lp_arm1_dff = arm1_dff.copy()\n",
    "    if len(arm1_pc_idx) != 0:\n",
    "        arm1_pc_dff = calculate_dff_with_moving_percentile(arm1_fluo[arm1_pc_idx], frame_rate=frame_rate_arm1, moving_window=60, percentile=50)\n",
    "        lp_arm1_dff[arm1_pc_idx] = arm1_pc_dff\n",
    "    lp_arm1_dff[arm1_pc_idx] = butter_filter(lp_arm1_dff[arm1_pc_idx], cutoff=0.5, fs=frame_rate_arm1, filter_type='low', order=5)\n",
    "    np.save(os.path.join(arm1_img_path, 'dff_moving_percentile_pc_lowpass_0p5hz.npy'), lp_arm1_dff)\n",
    "    lp_arm2_dff = arm2_dff.copy()\n",
    "    if len(arm2_pc_idx) != 0:\n",
    "        arm2_pc_dff = calculate_dff_with_moving_percentile(arm2_fluo[arm2_pc_idx], frame_rate=frame_rate_arm2, moving_window=60, percentile=50)\n",
    "        lp_arm2_dff[arm2_pc_idx] = arm2_pc_dff\n",
    "    lp_arm2_dff[arm2_pc_idx] = butter_filter(lp_arm2_dff[arm2_pc_idx], cutoff=0.5, fs=frame_rate_arm2, filter_type='low', order=5)\n",
    "    np.save(os.path.join(arm2_img_path, 'dff_moving_percentile_pc_lowpass_0p5hz.npy'), lp_arm2_dff)\n",
    "    arm1_dff = np.load(os.path.join(arm1_img_path, 'dff_moving_percentile_pc_lowpass_0p5hz.npy'))\n",
    "    arm2_dff = np.load(os.path.join(arm2_img_path, 'dff_moving_percentile_pc_lowpass_0p5hz.npy'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iblenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
